<div align="center">
<h1>FireRedASRï¼šå¼€æºå·¥ä¸šçº§è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹</h1>
</div>
[[è®ºæ–‡]](https://arxiv.org/pdf/2501.14350)
[[æ¨¡å‹]](https://huggingface.co/fireredteam)
[[åšå®¢]](https://fireredteam.github.io/demos/firered_asr/)
[[æ¼”ç¤º]](https://huggingface.co/spaces/FireRedTeam/FireRedASR)

FireRedASR æ˜¯ä¸€ç³»åˆ—å¼€æºçš„å·¥ä¸šçº§è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­æ–‡ã€ä¸­æ–‡æ–¹è¨€å’Œè‹±æ–‡ï¼Œè¾¾åˆ°äº†å…¬å¼€ä¸­æ–‡ ASR åŸºå‡†ä¸Šçš„æ–°æœ€å…ˆè¿›æ°´å¹³ï¼ˆSOTAï¼‰ï¼ŒåŒæ—¶åœ¨æ­Œæ›²æ­Œè¯è¯†åˆ«æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¥ æœ€æ–°åŠ¨æ€
- [2025/02/17] æˆ‘ä»¬å‘å¸ƒäº† [FireRedASR-LLM-L](https://huggingface.co/fireredteam/FireRedASR-LLM-L/tree/main) æ¨¡å‹æƒé‡ã€‚
- [2025/01/24] æˆ‘ä»¬å‘å¸ƒäº†[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2501.14350)ã€[åšå®¢](https://fireredteam.github.io/demos/firered_asr/)ä»¥åŠ [FireRedASR-AED-L](https://huggingface.co/fireredteam/FireRedASR-AED-L/tree/main) æ¨¡å‹æƒé‡ã€‚

## æ–¹æ³•
FireRedASR è®¾è®¡ç”¨äºæ»¡è¶³å„ç§åº”ç”¨åœºæ™¯ä¸­å¯¹é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡çš„éœ€æ±‚ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå˜ä½“ï¼š
- FireRedASR-LLMï¼šæ—¨åœ¨å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½å¹¶æ”¯æŒæ— ç¼ç«¯åˆ°ç«¯è¯­éŸ³äº¤äº’ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ç¼–ç å™¨-é€‚é…å™¨-å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚
- FireRedASR-AEDï¼šåœ¨é«˜æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå¹¶ä½œä¸ºåŸºäº LLM çš„è¯­éŸ³æ¨¡å‹ä¸­çš„æœ‰æ•ˆè¯­éŸ³è¡¨ç¤ºæ¨¡å—ã€‚å®ƒä½¿ç”¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆAEDï¼‰æ¶æ„ã€‚
![Model](/assets/FireRedASR_model.png)

## è¯„ä¼°
ç»“æœä»¥å­—ç¬¦é”™è¯¯ç‡ï¼ˆCER%ï¼‰è¡¨ç¤ºä¸­æ–‡ï¼Œä»¥å•è¯é”™è¯¯ç‡ï¼ˆWER%ï¼‰è¡¨ç¤ºè‹±æ–‡ã€‚
### å…¬å¼€ä¸­æ–‡ ASR åŸºå‡†ä¸Šçš„è¯„ä¼°
| æ¨¡å‹            | å‚æ•°é‡ | aishell1 | aishell2 | ws\_net  | ws\_meeting | å¹³å‡-4 |
|:----------------:|:-------:|:--------:|:--------:|:--------:|:-----------:|:---------:|
| FireRedASR-LLM   | 8.3B | 0.76 | 2.15 | 4.60 | 4.67 | 3.05 |
| FireRedASR-AED   | 1.1B | 0.55 | 2.52 | 4.88 | 4.76 | 3.18 |
| Seed-ASR         | 12B+ | 0.68 | 2.27 | 4.66 | 5.69 | 3.33 |
| Qwen-Audio       | 8.4B | 1.30 | 3.10 | 9.50 | 10.87 | 6.19 |
| SenseVoice-L     | 1.6B | 2.09 | 3.04 | 6.01 | 6.73 | 4.47 |
| Whisper-Large-v3 | 1.6B | 5.14 | 4.96 | 10.48 | 18.87 | 9.86 |
| Paraformer-Large | 0.2B | 1.68 | 2.85 | 6.74 | 6.97 | 4.56 |
`ws` è¡¨ç¤º WenetSpeechã€‚

### å…¬å¼€ä¸­æ–‡æ–¹è¨€å’Œè‹±æ–‡ ASR åŸºå‡†ä¸Šçš„è¯„ä¼°
| æµ‹è¯•é›†       | KeSpeech | LibriSpeech test-clean | LibriSpeech test-other  |
| :------------:| :------: | :--------------------: | :----------------------:|
|FireRedASR-LLM | 3.56 | 1.73 | 3.67 |
|FireRedASR-AED | 4.48 | 1.93 | 4.44 |
|ä»¥å¾€æœ€å…ˆè¿›ç»“æœ   | 6.70 | 1.82 | 3.50 |

## ä½¿ç”¨æ–¹å¼
ä» [HuggingFace](https://huggingface.co/fireredteam) ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¹¶å°†å…¶æ”¾ç½®åœ¨ `pretrained_models` æ–‡ä»¶å¤¹ä¸­ã€‚
å¦‚æœä½ æƒ³ä½¿ç”¨ `FireRedASR-LLM-L`ï¼Œè¿˜éœ€è¦ä¸‹è½½ [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) å¹¶å°†å…¶æ”¾åœ¨ `pretrained_models` æ–‡ä»¶å¤¹ä¸­ã€‚ç„¶åè¿›å…¥ `FireRedASR-LLM-L` æ–‡ä»¶å¤¹å¹¶è¿è¡Œå‘½ä»¤ï¼š`$ ln -s ../Qwen2-7B-Instruct`

### å®‰è£…è®¾ç½®
åˆ›å»º Python ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–é¡¹
```bash
$ git clone https://github.com/FireRedTeam/FireRedASR.git
$ conda create --name fireredasr python=3.10
$ pip install -r requirements.txt
```
è®¾ç½® Linux è·¯å¾„å’Œ PYTHONPATHï¼š
```
$ export PATH=$PWD/fireredasr/:$PWD/fireredasr/utils/:$PATH
$ export PYTHONPATH=$PWD/:$PYTHONPATH
```
å°†éŸ³é¢‘è½¬æ¢ä¸º 16kHzã€16ä½ PCM æ ¼å¼ï¼š
```
ffmpeg -i input_audio -ar 16000 -ac 1 -acodec pcm_s16le -f wav output.wav
```

### å¿«é€Ÿå¼€å§‹
```bash
$ cd examples
$ bash inference_fireredasr_aed.sh
$ bash inference_fireredasr_llm.sh
```

### å‘½ä»¤è¡Œä½¿ç”¨æ–¹å¼
```bash
$ speech2text.py --help
$ speech2text.py --wav_path examples/wav/BAC009S0764W0121.wav --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L
$ speech2text.py --wav_path examples/wav/BAC009S0764W0121.wav --asr_type "llm" --model_dir pretrained_models/FireRedASR-LLM-L
```

### Python ä½¿ç”¨æ–¹å¼
```python
from fireredasr.models.fireredasr import FireRedAsr
batch_uttid = ["BAC009S0764W0121"]
batch_wav_path = ["examples/wav/BAC009S0764W0121.wav"]
# FireRedASR-AED
model = FireRedAsr.from_pretrained("aed", "pretrained_models/FireRedASR-AED-L")
results = model.transcribe(
    batch_uttid,
    batch_wav_path,
    {
        "use_gpu": 1,
        "beam_size": 3,
        "nbest": 1,
        "decode_max_len": 0,
        "softmax_smoothing": 1.25,
        "aed_length_penalty": 0.6,
        "eos_penalty": 1.0
    }
)
print(results)

# FireRedASR-LLM
model = FireRedAsr.from_pretrained("llm", "pretrained_models/FireRedASR-LLM-L")
results = model.transcribe(
    batch_uttid,
    batch_wav_path,
    {
        "use_gpu": 1,
        "beam_size": 3,
        "decode_max_len": 0,
        "decode_min_len": 0,
        "repetition_penalty": 3.0,
        "llm_length_penalty": 1.0,
        "temperature": 1.0
    }
)
print(results)
```

## ä½¿ç”¨æç¤º
### æ‰¹é‡æŸæœç´¢ï¼ˆBatch Beam Searchï¼‰
- åœ¨ä½¿ç”¨ FireRedASR-LLM è¿›è¡Œæ‰¹é‡æŸæœç´¢æ—¶ï¼Œè¯·ç¡®ä¿è¾“å…¥è¯­éŸ³çš„é•¿åº¦ç›¸è¿‘ã€‚å¦‚æœè¯­éŸ³é•¿åº¦å·®å¼‚è¾ƒå¤§ï¼Œè¾ƒçŸ­çš„è¯­éŸ³å¯èƒ½ä¼šå‡ºç°é‡å¤é—®é¢˜ã€‚ä½ å¯ä»¥é€šè¿‡æŒ‰é•¿åº¦æ’åºæ•°æ®é›†æˆ–è®¾ç½® `batch_size` ä¸º 1 æ¥é¿å…æ­¤é—®é¢˜ã€‚
### è¾“å…¥é•¿åº¦é™åˆ¶
- FireRedASR-AED æ”¯æŒæœ€é•¿ 60 ç§’çš„éŸ³é¢‘è¾“å…¥ã€‚è¶…è¿‡ 60 ç§’å¯èƒ½å¯¼è‡´å¹»è§‰é—®é¢˜ï¼Œè¶…è¿‡ 200 ç§’å°†å¼•å‘ä½ç½®ç¼–ç é”™è¯¯ã€‚
- FireRedASR-LLM æ”¯æŒæœ€é•¿ 30 ç§’çš„éŸ³é¢‘è¾“å…¥ã€‚å¯¹äºæ›´é•¿çš„è¾“å…¥è¡Œä¸ºç›®å‰æœªçŸ¥ã€‚

## è‡´è°¢
æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„è´¡çŒ®ï¼š
- [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)
- [icefall/ASR_LLM](https://github.com/k2-fsa/icefall/tree/master/egs/speech_llm/ASR_LLM)
- [WeNet](https://github.com/wenet-e2e/wenet)
- [Speech-Transformer](https://github.com/kaituoxu/Speech-Transformer)

## å¼•ç”¨
```bibtex
@article{xu2025fireredasr,
  title={FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration},
  author={Xu, Kai-Tuo and Xie, Feng-Long and Tang, Xu and Hu, Yao},
  journal={arXiv preprint arXiv:2501.14350},
  year={2025}
}
```
```